# SEER Data and Annotations

NOTE: You must obtain the original datasets licensing in order to use these annotations.

## MuSE
Request access to the original [MuSE dataset](https://ieeexplore.ieee.org/abstract/document/8682793/?casa_token=ZmgmPj71ylQAAAAA:PNN7pf9wpYrGOKfqpfdDaX-kUjGlEKaZmSkR4j7q8vsXbHNzlgyP9gfsQPQicPdYc0_OG3YqG_g) here: email emilykmp@umich.edu

Then, enter the `SEER` directory to access the CSVs `Task1_Data_MuSE_Release.csv` and `Task2_Data_MuSE_Release.csv`.

### Task 1 Data
- FileName: the wav file name from the original dataset
    - example: `06_DR-100_0093_5_sentence_7.wav`
- GPT4.1_EmoClass: the GPT4.1-labeled and human verified emotion class
    - emotion classes: disgust, contempt, angry, surprise, sad, happy, fear (neutral-labeled samples not included in Task 1)
- GPT4.1_EmoVal: the GPT4.1-labeled and human verified valence score
    - valence classes: positive, negative (neutral-labeled samples not included in Task 1)
- Transcription: generated with `openai/whisper-large-v2`
- Gold_Spans: expert emotion evidence annotations with inline labels via \*\* markers
    - example: "This is a \*\*very happy\*\* sentence"
- Annot{i}: crowdsourced emotion evidence annotations with inline labels via \*\* markers for annotator `i`

### Task 2 Data
- First_FileName: the first of the five consecutive wav-file name from the original dataset. If a file contained multiple sentences, it is split into `n` parts and relabeled with an additional `_sent{i}.wav`. 
    - example: `26_DR-100_0091_1_sentence_3_sent2.wav`
- Consecutive_FileNames: a string representation of an array containing 5 consecutive wav-file names from the original dataset.
- Sentence{i}_Transcript: the transcription for sentence `i`, generated with `openai/whisper-large-v2`
- Combined_Transcription: the combined transcript for five consecutive sentences
- Sentence{i}_Gold_EmoClass: the expert annotation for categorical emotion for sentence `i`
- Sentence{i}_Gold_EmoVal: the expert annotation for valence for sentence `i`
- Gold_Spans
- Annot{i}

## MSP-Podcast
Request access to the original [MSP-Podcast](https://arxiv.org/pdf/2509.09791v1) dataset version 1.11 here: https://www.lab-msp.com/MSP/MSP-Podcast.html

### Emotion Evidence Annotations on MSP-Podcast
To respect the licensing of MSP-Podcast, we provide emotion evidence span annotations as a list of word indices `[start_index,end_index)` (space-separated indices) that are relative to the original dataset's manual transcriptions. The emotion evidence span annotations were collected on transcriptions generated by `openai/whisper-large-v2`. We align the whisper-generated transcriptions with the manual transcriptions. Example: `[[0, 3], [5, 7]]` --> emotion evidence span from [0,3) and [5,7) when splitting the manual transcription by space. These lists of indices for the 'Gold_Spans' and 'Annot*' columns described below.

We provide scripts `MSP-Podcast1.11/map_task1_data_to_transcript.py` and `MSP-Podcast1.11/map_task2_data_to_transcript.py` to conveniently convert the index-based labels CSV to inline-marking when provided with the official MSP-Podcast1.11 transcript directory.

### Task 1 Data
- FileName: the wav file name from the original dataset
    - example: `MSP-PODCAST_0597_0382.wav`
- GPT4.1_EmoClass: the GPT4.1-labeled and human verified emotion class
    - emotion classes: disgust, contempt, angry, surprise, sad, happy, fear (neutral-labeled samples not included in Task 1)
- GPT4.1_EmoVal: the GPT4.1-labeled and human verified valence score
    - valence classes: positive, negative (neutral-labeled samples not included in Task 1)
- Gold_Spans: expert emotion evidence annotations provided as a string-representation of an array of indices corresponding to the space-split words of the original dataset's manual transcriptions (see paragraph above)
- Annot{i}: crowdsourced emotion evidence annotations via indicies (see Gold_Spans description) for annotator `i`

### Task 2 Data
- First_FileName: the first of the five consecutive wav-file name from the original dataset. 
    - example: `MSP-PODCAST_0202_0030.wav`
- Consecutive_FileNames: a string representation of an array containing up to 5 consecutive wav-file names from the original dataset. There may be less than 5 if one file contained > 1 sentence.
- Sentence{i}_Gold_EmoClass: the expert annotation for categorical emotion for sentence `i`
- Sentence{i}_Gold_EmoVal: the expert annotation for valence for sentence `i`
- Gold_Spans: expert emotion evidence annotations provided as a string-representation of an array of indices corresponding the the space-split words of the original dataset's manual transcriptions **when all five sentences are joined together**.
- Annot{i}: crowdsourced emotion evidence annotations via indicies (see Gold_Spans description) for annotator `i`
- FileWordRanges: a string-representation of an array with length equal to that of Consecutive_FileNames. Array entry at index `k` is a range representing the start and end indices of `Consecutive_FileNames[k]`'s transcription when all five sentences are joined together.
    - example: `[[0, 26], [26, 43]]` --> `Consecutive_FileNames[0]` comprises indices [0,26) in the combined five-sentence transcription.
- Sentence{i}_WordRange: a string-representation of a pair of [start,end) indices that indicate which indices in the five-sentence combined transcript correspond to sentence `i`.
    - example: FileWordRanges = `[[0, 26], [26, 43]]`, and Sentence1_WordRanges = `[1, 16]` --> Sentence2 corresponds to words [1,16) in `Consecutive_FileNames[0]`

